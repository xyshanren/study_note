<!--
 * @Autor: 李逍遥
 * @Date: 2021-03-21 12:02:04
 * @LastEditors: 李逍遥
 * @LastEditTime: 2021-03-21 23:58:49
 * @Descriptiong: 
-->

# 目录 #

- [目录](#目录)
- [HADOOP](#hadoop)
  - [安装和配置](#安装和配置)
    - [安装jdk环境](#安装jdk环境)
  - [安装配置Hadoop2](#安装配置hadoop2)

# HADOOP #

The Apache™ Hadoop® project develops open-source software for reliable, scalable, distributed computing.  

The Apache Hadoop software library is a framework that allows for the distributed processing of large data sets across clusters of computers using simple programming models. It is designed to scale up from single servers to thousands of machines, each offering local computation and storage. Rather than rely on hardware to deliver high-availability, the library itself is designed to detect and handle failures at the application layer, so delivering a highly-available service on top of a cluster of computers, each of which may be prone to failures.  

## 安装和配置 ##

>以centos7系统为例，jdk版本为Java8，hadoop版本为2.10  

### 安装jdk环境 ###

>在root用户下安装  

- 使用Linux通用包进行安装  

    ```shell
    # 解压
    tar xf jdk-8u281-linux-x64.tar.gz
    # 创建目录
    mkdir /application
    # 移动到刚刚创建的目录中
    mv jdk1.8.0_281 /application/
    # 创建jdk的软连接
    ln -s /application/jdk1.8.0_281 /application/jdk
    # 验证jdk是否安装成功
    cd /application/jdk/bin
    ./java -version
    ```

- 配置JAVA_HOME环境变量  

    ```shell
    # 编辑全局配置文件
    vim /etc/profile
    # 添加以下配置项
    export JAVA_HOME=/application/jdk
    export PATH=$PATH:$JAVA_HOME/bin
    # 使配置生效
    source /etc/profile
    # 验证
    java -version
    ```

## 安装配置Hadoop2 ##

- 创建hadoop用户  

    ```shell
    # 创建一个可登陆的用户
    useradd -m hadoop -s /bin/bash
    # 设置密码
    passwd hadoop
    # 为hadoop用户增加管理员权限
    visudo
    # 找到 root ALL=(ALL) ALL 这行(应该在100行，可以使用```:98```命令直接跳转到100行)
    # 然后在这行下面增加一行内容 hadoop ALL=(ALL) ALL（其中的间隔符使用tab），然后保存修改；
    hadoop ALL=(ALL) ALL
    ```

- 安装hadoop  

    ```shell
    # 解压
    tar xf hadoop-2.10.0.tar.gz
    # 移动到刚刚创建的目录中
    mv hadoop-2.10.0 /application/
    # 赋予hadoop用户权限
    chown -R hadoop:hadoop /application/hadoop-2.10.0
    # 切换到hadoop用户
    su hadoop
    # 创建jdk的软连接
    sudo ln -s /application/hadoop-2.10.0 /application/hadoop
    # 验证是否安装成功
    cd /application/hadoop/bin
    ./hadoop version
    ```

- 配置hadoop环境变量  

    ```shell
    # 编辑全局配置文件
    sudo vim /etc/profile
    # 添加以下配置项
    export HADOOP_HOME=/application/hadoop
    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
    # 使配置生效
    sudo source /etc/profile
    # 验证
    hadoop version
    ```

- 本地模式:standalone(local)  
  安装好hadoop之后就是本地模式，使用的就是centos的文件系统，不需要启动单独的hadoop进程。  

- 伪分布式:Pseudodistributed mode  
  - 进入${HADOOP_HOME}/etc/hadoop目录配置四个文件  

    ```txt
    core-site.xml
    hdfs-site.xml
    mapred-site.xml
    yarn-site.xml
    后两个是yarn的配置文件，如果不需要启动yarn的话，可以不用配置
    ```

  - 在 core-site.xml 中增加以下配置  

    ```xml
    <configuration>
        <property>
            <name>fs.defaultFS</name>
            <value>hdfs://localhost:9000</value>
        </property>
    </configuration>
    ```

  - 在 hdfs-site.xml 中增加以下配置  

    ```xml
    <configuration>
        <property>
            <name>dfs.replication</name>
            <value>1</value>
        </property>
    </configuration>
    ```

  - 在 mapred-site.xml 中增加以下配置  
    注意，要先复制 mapred-site.xml.template 为 mapred-site.xml 文件  

    ```xml
    <configuration>
        <property>
            <name>mapreduce.framework.name</name>
            <value>yarn</value>
        </property>
    </configuration>
    ```

  - 在 yarn-site.xml 中增加以下配置  

    ```xml
    <configuration>
        <property>
            <name>yarn.resourcemanager.hostname</name>
            <value>localhost</value>
        </property>
        <property>
            <name>yarn.nodemanager.aux-services</name>
            <value>mapreduce_shuffle</value>
        </property>
    </configuration>
    ```

  - 配置本机的SSH免密登录  
    即在本地配置ssh登录，配置方法见 linux/使用笔记  
    另外，最好配置下主机名和静态ip，配置方法见 linux/使用笔记 和 开发环境/为virtual虚拟机设置静态ip  

  - 配置完后格式化文件系统  
    `hadoop namenode -format`  

  - 启动hadoop  
    `start-all.sh`

  - 通过 `jps` 查看是否启动成功  

  - 关闭hadoop  
    `stop-all.sh`

  - 报错  
    报错信息如下：  

    ```shell
    [hadoop@c01 download]$ start-all.sh
    This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
    Starting namenodes on [localhost]
    localhost: Error: JAVA_HOME is not set and could not be found.
    localhost: Error: JAVA_HOME is not set and could not be found.
    Starting secondary namenodes [0.0.0.0]
    0.0.0.0: Error: JAVA_HOME is not set and could not be found.
    starting yarn daemons
    starting resourcemanager, logging to /application/hadoop-2.10.0/logs/yarn-hadoop-resourcemanager-c01.out
    localhost: Error: JAVA_HOME is not set and could not be found.

    # 需要修改 hadoop-env.sh 文件中的 Java配置
    [hadoop@c01 hadoop]$ vim /application/hadoop/etc/hadoop/hadoop-env.sh
    # 找到以下配置
    export JAVA_HOME=${JAVA_HOME}
    # 将 JAVA_HOME 修改为实际值
    export JAVA_HOME=/application/jdk
    ```
